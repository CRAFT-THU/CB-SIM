/// automatic generate file

#ifndef _STAGE_CONV_${layer_num}
#define _STAGE_CONV_${layer_num}

#include "../${crossbar_file}"
#include "systemc.h"
#include "../ADC.h"
#include "../DAC.h"
#include <omp.h>

using namespace std;

// fifth convolution layer, input channel ${input_channel}, output channel ${output_channel}, pooling ${pooling_size}

// #define POOLING_SIZE ${pooling_size}

SC_MODULE(stage_conv_${layer_num}) {
	sc_in<float> *input;
	sc_out<float> *output;
	sc_in<int> signal_in;
	sc_out<int> signal_out;

	CROSSBAR cb;
	float **pooling_buffer;
	int pooling_pointer;
	int print;

	float *input_buff;
	float *ad_buff;

	// read crossbar data from file
	void init_crossbar() {
		// read from convolution layer ${layer_num}
		float* cell = new float[CROSSBAR_L*CROSSBAR_W];
		string filename = "./weights/weight_${layer_num}.csv";
		ifstream inFile_x(filename.c_str(), ios::in);
		for (int i = 0; i < CROSSBAR_L; i++) {
			string lineStr_x;
			getline(inFile_x, lineStr_x); // read one row data
			stringstream ss(lineStr_x);
			string str;
			for (int j = 0; j < CROSSBAR_W; j++) {
				// cell[i*CROSSBAR_W + j] = i * CROSSBAR_W + j;
				getline(ss, str, ',');
				istringstream iss(str);
				float num;
				iss >> num;
				cell[i*CROSSBAR_W + j] = num;
			}
		}
        inFile_x.close();
		cout << "weight here is " << cell[CROSSBAR_W*(CROSSBAR_L-1)] << endl;
		cb.init(cell, 1, CROSSBAR_L, CROSSBAR_W);

		// copy layer ${layer_num} weight matrix to entire_cb weight matrix
		int start_pos = (${layer_num}-1)*CROSSBAR_L*ENTIRE_W+(${layer_num}-1)*CROSSBAR_W;
		for (int i = 0; i < CROSSBAR_L; i++) {
			memcpy(entire_cb.CB_cell+start_pos+i*ENTIRE_W, cell+i*CROSSBAR_W, CROSSBAR_W*sizeof(float));
		}
		cout << "weight here is " << entire_cb.CB_cell[start_pos+(CROSSBAR_L-1)*ENTIRE_W] << endl;

		delete[] cell;
		cout << "load weights ${layer_num} complete. " << filename << endl;
		// cb.printcrossbar();
		// parameters initialize
		pooling_pointer = 0;
		print = 0;
		input_buff = new float[INPUT_SIZE*${input_channel}]();
		ad_buff = new float[CROSSBAR_W]();
		input = new sc_in<float>[INPUT_SIZE*${input_channel}]();
		output = new sc_out<float>[${output_channel}]();
		pooling_buffer = new float*[${output_channel}];
		for (int i = 0; i < ${output_channel}; ++i) {
			pooling_buffer[i] = new float[${image_size}*${pooling_size}]();
		}
	}

	// activation function default relu
	void activation(float tmp_input[]) {
		for (int i = 0; i < ${output_channel}; i++)
			if (tmp_input[i] < 0.0)
				tmp_input[i] = 0.0;
	}

	void add_to_pooling_buffer(float tmp_input[]) {
		for (int i = 0; i < ${output_channel}; i++){
			pooling_buffer[i][pooling_pointer] = tmp_input[i];
		}
	}

	// do maxpooling
	void max_pooling() {
		float tmp_output[${output_channel}];
		int x = pooling_pointer / ${image_size};
		int y = pooling_pointer % ${image_size};

		if ((x % ${pooling_size} == (${pooling_size} - 1)) && (y % ${pooling_size} == (${pooling_size} - 1))) {
			for (int i = 0; i < ${output_channel}; i++) {
				float _max = 0.0; // can not be smaller than 0.0 after relu
				for (int j = 0; j < ${pooling_size}; j++){
					for (int k = 0; k < ${pooling_size}; k++){
						float element = pooling_buffer[i][(x - j) % ${pooling_size}*${image_size} + (y - k)];
						if (element > _max)
							_max = element;
					}
				}
				tmp_output[i] = _max;
			}

			// send to next layer (next buffer)
			for (int i = 0; i < ${output_channel}; i++) {
				output[i].write(tmp_output[i]);
			}
			signal_out.write(signal_in.read());
		}
		pooling_pointer++;
		if (pooling_pointer >= ${image_size} * ${pooling_size})
			pooling_pointer = 0;
	}

	// run convolution
	void stage_conv_run() {
		// with ad & da
		// read data
		memset(input_buff, 0, sizeof(float)*INPUT_SIZE*${input_channel});
		float _max = 0.0;
		for (int i = 0; i < INPUT_SIZE*${input_channel}; ++i){
			input_buff[i] = input[i].read();
			if (input_buff[i] > _max)
				_max = input_buff[i];
		}

		// for movement
		int move = 0;
		for (int i = 0; i < DA_WIDTH; ++i){
			move += int(pow(2, double(i)));
		}

		// scale input
		int n = 0;

		if (${layer_num} == 1)
			n = 8;
		else if (${layer_num} == 2)
			n = 15;
		else n = 14;
		if (n > AD_WIDTH){
			float para = pow(2, AD_WIDTH-n);
			for (int i = 0; i < INPUT_SIZE*${input_channel}; ++i){
				input_buff[i] = int(input_buff[i] * para);
				if (input_buff[i] > 255)
					input_buff[i] = 255;
			}
		}

		// DA->XB->AD
		da dac(DA_V);
		ad adc(AD_V);
		memset(ad_buff, 0, sizeof(float)*CROSSBAR_W);
		for (int i = 0; i < AD_WIDTH/DA_WIDTH; ++i){
			float tmp_input[CROSSBAR_L] = { 0.0 };
			float tmp_output[CROSSBAR_W] = { 0.0 };
			// lower da_width bits
			for (int j = 0; j < INPUT_SIZE*${input_channel}; ++j){
				int bitnum = static_cast<int>(int(input_buff[j]) & move);
				dac.trans(bitnum, DA_WIDTH);
				tmp_input[CROSSBAR_L - INPUT_SIZE * ${input_channel} + j] = float(bitnum);
				input_buff[j] = input_buff[j] / pow(2, DA_WIDTH);
			}
			cb.run(tmp_input, tmp_output, false);
			// ad and shift add
			for (int j = 0; j < CROSSBAR_W; ++j){
				float tmp = tmp_output[j] / XB${layer_num}_I;
				if (tmp > 1)
					adc.trans(1.0);
				else if (tmp < -1)
					adc.trans(-1.0);
				else
					adc.trans(tmp);
				int tmp_ad = int(adc.AD_out);
				ad_buff[j] = (tmp_ad) * pow(2, i) + ad_buff[j];
			}
		}

		activation(ad_buff);
		add_to_pooling_buffer(ad_buff);

		max_pooling(); // pooling size ${pooling_size}

	}

	SC_CTOR(stage_conv_${layer_num}) {
		init_crossbar();

		SC_METHOD(stage_conv_run);
		sensitive << signal_in;
		dont_initialize();
	}

	~stage_conv_${layer_num}() {
		cb.free_space();
		delete []input_buff;
		delete []ad_buff;
		delete []input;
		delete []output;
		for (int i=0; i<${output_channel}; i++){
			delete []pooling_buffer[i];
		}
		delete pooling_buffer;
	}
};

#endif // !_STAGE_CONV_${layer_num}
